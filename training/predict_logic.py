import cv2
import numpy as np
from ultralytics import YOLO
import os

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = 'runs/detect/math_yolo_run/weights/best.pt' # ä½ çš„æ¨¡åž‹è·¯å¾„
TARGET_SIZE = 640                                       # è®­ç»ƒæ—¶çš„ imgsz
CONF_THRESHOLD = 0.25                                   # ç½®ä¿¡åº¦é˜ˆå€¼
# ===========================================

def resize_and_pad(img, size=640, pad_color=(255, 255, 255)):
    """
    å°†å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼Œå¹¶å¡«å……æˆæ­£æ–¹å½¢ï¼Œé˜²æ­¢å˜å½¢ã€‚
    """
    h, w = img.shape[:2]
    sh, sw = size, size
    interp = cv2.INTER_AREA if h > sh or w > sw else cv2.INTER_CUBIC
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    aspect = w / h
    if aspect > 1: # æ¨ªå›¾
        new_w = sw
        new_h = np.round(sw / aspect).astype(int)
        pad_vert = (sh - new_h) / 2
        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)
        pad_left, pad_right = 0, 0
    elif aspect < 1: # ç«–å›¾
        new_h = sh
        new_w = np.round(sh * aspect).astype(int)
        pad_horz = (sw - new_w) / 2
        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)
        pad_top, pad_bot = 0, 0
    else: # æ­£æ–¹å½¢
        new_h, new_w = sh, sw
        pad_top, pad_bot, pad_left, pad_right = 0, 0, 0, 0

    # ç¼©æ”¾
    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)
    # å¡«å……èƒŒæ™¯è‰²
    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, 
                                   borderType=cv2.BORDER_CONSTANT, value=pad_color)
    return scaled_img

def run_debug_test(image_path):
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡åž‹æ–‡ä»¶ {MODEL_PATH}")
        return

    # 1. åŠ è½½æ¨¡åž‹
    model = YOLO(MODEL_PATH)
    
    # 2. è¯»å–å¹¶é¢„å¤„ç†å›¾ç‰‡
    raw_img = cv2.imread(image_path)
    if raw_img is None:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ {image_path}")
        return

    # å…³é”®æ­¥éª¤ï¼šè¡¥é½ä¸ºæ­£æ–¹å½¢
    processed_img = resize_and_pad(raw_img, size=TARGET_SIZE)
    
    # 3. æŽ¨ç†
    results = model.predict(processed_img, conf=CONF_THRESHOLD)
    res = results[0]

    # 4. å¯è§†åŒ–ä¿å­˜ï¼ˆéžå¸¸é‡è¦ï¼Œä¸€çœ¼çœ‹å‡ºæ¨¡åž‹åœ¨çœ‹å“ªï¼‰
    debug_img = res.plot()
    cv2.imwrite("debug_inference_view_2.jpg", debug_img)
    print("ðŸ“‚ è°ƒè¯•å›¾å·²ä¿å­˜è‡³: debug_inference_view_2.jpg")

    # 5. è§£æžå¹¶æŽ’åº
    detections = []
    for box in res.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        bbox = box.xyxy[0].cpu().numpy() # [x1, y1, x2, y2]
        x_center = (bbox[0] + bbox[2]) / 2
        
        detections.append({
            'name': model.names[cls_id],
            'x_center': x_center,
            'conf': conf
        })

    if not detections:
        print("âš ï¸ ç»“æžœ: æœªè¯†åˆ«åˆ°ä»»ä½•å­—ç¬¦ã€‚è¯·æ£€æŸ¥è°ƒè¯•å›¾ï¼Œå¯èƒ½æ˜¯æ¨¡åž‹ç½®ä¿¡åº¦å¤ªä½Žæˆ–èƒŒæ™¯è‰²åè½¬ã€‚")
        return

    # æŒ‰ X è½´åæ ‡ä»Žå·¦åˆ°å³æŽ’åº
    detections.sort(key=lambda x: x['x_center'])
    
    # æ˜ å°„ç¬¦å·å¹¶æ‹¼æŽ¥
    raw_eq = "".join([d['name'] for d in detections])
    calc_eq = raw_eq.replace('times', '*').replace('div', '/').replace('add', '+').replace('sub', '-')
    
    print("-" * 30)
    print(f"ðŸ“Œ è¯†åˆ«åºåˆ—: {raw_eq}")
    print(f"ðŸ“Œ å¾…ç®—ç®—å¼: {calc_eq}")
    
    # 6. å®‰å…¨è®¡ç®—
    try:
        # åªå…è®¸æ•°å­—å’Œè¿ç®—ç¬¦è¿›å…¥ eval
        # æ³¨æ„ï¼šè¿™é‡Œç›´æŽ¥ç”¨ eval ä»…é™æœ¬åœ°æµ‹è¯•ï¼ŒStreamlit å»ºè®®ç”¨æ›´å®‰å…¨çš„åº“
        result = eval(calc_eq)
        print(f"âœ… è®¡ç®—ç­”æ¡ˆ: {result}")
    except Exception as e:
        print(f"âŒ è®¡ç®—å¤±è´¥: {e} (è¯·æ£€æŸ¥ç®—å¼é€»è¾‘æ˜¯å¦å®Œæ•´ï¼Œå¦‚æ‹¬å·æ˜¯å¦é—­åˆ)")

if __name__ == "__main__":
    # å¡«å…¥ä½ æƒ³è¦æµ‹è¯•çš„å›¾ç‰‡è·¯å¾„
    test_image_path = "test_handwriting_2.jpg" 
    run_debug_test(test_image_path)